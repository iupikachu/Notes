## **高性能Mysql **

笔记来源于        极客时间     《Mysql实战45讲》—— 丁奇   

​							 中华石杉	 《从零开始带你成为MySQL实战优化高手》 ——救火队长



### 1.基础架构

<img src="Mysql 实战.assets/image-20210511153212957.png" alt="image-20210511153212957" style="zoom:50%;" />



* Server 层
  * 连接器
  * 查询缓存
  * 分析器
  * 优化器
  * 执行器
* 存储引擎层
  * InnoDB
  * MyISAM
  * Memory



**不同的存储引擎共用一个 Server层**



#### 1.1 连接器

第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端**建立连接**、**获取权限**、**维持和管理连接**。连接命令一般是这么写的：

```mysql
mysql -h$ip -P$port -u$user -p
```

在完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。

如果用户名或密码不对，你就会收到一个"Access denied for user"的错误，然后客户端程序结束执行。

如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。



连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 show processlist 命令中看到它。其中的 Command 列显示为“Sleep”的这一行，就表示现在系统里面有一个空闲连接。

<img src="Mysql 实战.assets/f2da4aa3a672d48ec05df97b9f992fed.png" alt="f2da4aa3a672d48ec05df97b9f992fed" style="zoom:67%;" />

​		客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 **wait_timeout** 控制的，默认值是 8 小时。

​		**长连接**:	连接成功后，如果客户端持续有请求，则一直使用同一个连接		

​		**短连接:**	每次执行完很少的几次查询就断开连接，下次查询再重新建立一个

​		建立连接的过程比较复杂,尽量使用长连接。但是因为mysql执行过程中临时使用的内存是管理在连接对象中的，这些资源在		连接断开时才会释放，所以长连接不断累积，会导致内存占用太大，被系统强行杀掉(OOM)，会看到mysql异常重启了。

​		解决方法:

​			1. 定期断开长连接。使用一段时间或者执行过一次占用大内存的大查询后断开，要查询的话再重连

​			2. Mysql 5.7 或更新的版本，可以在执行较大操作后，执行 **mysql_reset_connection** 重新初始化连接资源，这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完的状态。

<img src="Mysql 实战.assets/image-20210513150622316.png" alt="image-20210513150622316" style="zoom:80%;" />

连接池：c3p0 druid

数据库端连接池与客户端连接池是一一对应的。

网络连接需要后台线程去监听端口和解析数据。



#### 1.2 查询缓存



MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。

之前执行过的语句及其结果可能会以 **key-value** 对的形式，被直接缓存在内存中。

key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。

如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。



**但是大多数情况下我会建议不要使用查询缓存**

查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。

MySQL 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻底没有这个功能了。



#### 1.3 分析器

如果没有命中查询缓存，就要开始真正执行语句了。



* **词法分析**：MySQL 需要识别出里面的字符串分别是什么，代表什么。比如说：把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”。

* **语法分析: ** 根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。

  如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒，一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接“use near”的内容。



#### 1.4  优化器

经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。

优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。



```mysql

mysql> select * from t1 join t2 using(ID)  where t1.c=10 and t2.d=20;

```



* 既可以先从表 t1 里面取出 c=10 的记录的 ID 值，再根据 ID 值关联到表 t2，再判断 t2 里面 d 的值是否等于 20。
* 也可以先从表 t2 里面取出 d=20 的记录的 ID 值，再根据 ID 值关联到 t1，再判断 t1 里面 c 的值是否等于 10。

这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。





#### 1.5 执行器



MySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。



* 先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误。

* 如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。

```mysql

mysql> select * from T where ID=10;

ERROR 1142 (42000): SELECT command denied to user 'b'@'localhost' for table 'T'
```





**执行器的执行流程：**

1. 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；

2. 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。

3. 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。



在数据库的慢查询日志中看到一个 **rows_examined** 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。

执行器调用一次，在引擎内部则扫描了多行，因此**引擎扫描行数**跟 **rows_examined** 并不是完全相同的。





> 如果表 T 中没有字段 k，而你执行了这个语句 select * from T where k=1, 那肯定是会报“不存在这个列”的错误： “Unknown column ‘k’ in ‘where clause’”。你觉得这个错误是在我们上面提到的哪个阶段报出来的呢？



分析器



总的流程分析 :

1. java客户端程序通过 mysql数据库驱动与 mysql建立网络连接 （建立连接和关闭连接耗时较大，所以使用了连接池）
2. 数据库后台线程接收到请求拿到数据，查询一下在不在缓存中。
3. 通过sql接口执行，分析器分析sql语句。识别一下表、变量，语法检查一下。
4. 优化器，生成最优的执行计划
5. 执行器判断有没有权限，调用存储引擎的接口去完成执行计划 (操作磁盘数据)



### 2.日志系统



一条更新语句的执行流程又是怎样的呢？MySQL 可以恢复到半个月内任意一秒的状态，惊叹的同时，你是不是心中也会不免会好奇，这是怎样做到的呢？



两个重要的日志模块:

1.  **redo log** （重做日志）
2.  **bin log**  (归档日志)



#### 2.1 redo log

WAL 技术 Write-Ahead Logging 先写日志，再写磁盘。

具体来说，当有一条记录需要更新的时候，InnoDB 引擎会先把记录写到 redo log ，并更新内存，这个时候更新就算完成了，同时，InnoDB引擎会在适当的时候将这个操作记录更新到磁盘，而这个更新往往是在系统比较空闲的时候。



例子: 	粉板(redo log)	 账本(bin log)

如果今天赊账的不多，掌柜可以等打烊后再整理。但如果某天赊账的特别多，粉板写满了，又怎么办呢？这个时候掌柜只好放下手中的活儿，把粉板中的一部分赊账记录更新到账本中，然后把这些记录从粉板上擦掉，为记新账腾出空间。



与此类似，InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。



<img src="Mysql 实战.assets/16a7950217b3f0f4ed02db5db59562a7.png" alt="16a7950217b3f0f4ed02db5db59562a7" style="zoom:67%;" />





write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。



write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。



有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 **crash-safe** 。数据库重启了，**内存中的数据页没有同步到磁盘中**，可以通过redo log日志恢复。



#### 2.2 bin log

MySQL 整体来看，其实就有两块：一块是 Server 层，它主要做的是 MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。



上面的粉板 redo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志）。



> 为什么会有两份日志呢？

最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。



**redo log 和 bin log 的不同处:**

1. redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。

2. redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。

3. redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

   

执行器和 InnerDB引擎在执行这条 Update语句的流程:

1. 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。
2. 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。
3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。
4. 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。
5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。



update 语句的执行流程图，图中浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的。

<img src="Mysql 实战.assets/2e5bff4910ec189fe1ee6e2ecc7b4bbe.png" alt="2e5bff4910ec189fe1ee6e2ecc7b4bbe" style="zoom:67%;" />



redo log 的写入拆成了两步: prepare commit  这就是 **两阶段提交**

如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。

> 这个概率是不是很低，平时也没有什么动不动就需要恢复临时库的场景呀？



其实不是的，不只是误操作后需要用这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用**全量备份**加上应用 **binlog** 来实现的，这个“不一致”就会导致你的线上出现**主从数据库不一致**的情况。



简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。

redolog和binlog具有关联行，在恢复数据时，redolog用于恢复主机故障时的未更新的物理数据，binlog用于备份操作。

每个阶段的log操作都是记录在磁盘的，在恢复数据时，redolog 状态为commit则说明binlog也成功，直接恢复数据；

如果redolog是prepare，则需要查询对应的binlog事务是否成功，决定是回滚还是执行。

**通过查看redo日志状态，手工决定后续操作，以此来保证数据一致性。**





**两个重要参数**

redo log 用于保证 crash-safe 能力。**innodb_flush_log_at_trx_commit** 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。

**sync_binlog** 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。









**分析一条 update 语句**

```sql
#原先的 name = 'zhangsan'
update users set name = 'xxx' where id =10
```



innoDB 会先将 "id = 10"这一行数据看看是否在缓冲池里，如果不在的话会直接从磁盘里加载到缓冲池里，而且还会对这行记录加**独占锁**。

<img src="Mysql 实战.assets/image-20210517094548955.png" alt="image-20210517094548955" style="zoom:50%;" />





innodb把要更新的值 zhangsan id=10 这些信息写入到 **undo日志**中。

<img src="Mysql 实战.assets/image-20210517094738587.png" alt="image-20210517094738587" style="zoom:50%;" />



先更新内存缓冲池中的记录，此时这个记录就是**脏数据**。

磁盘上这行数据的 name 还是 zhangsan , 但是内存里这行数据已经被修改了。

<img src="Mysql 实战.assets/image-20210517095035020.png" alt="image-20210517095035020" style="zoom:50%;" />



为了避免此时mysql宕机，导致内存中的数据丢失，此时把对内存所做的修改写入到 **Redo Log Buffer** 中。

redo日志，其实就是记录修改 id=10 修改了name 字段为xxx。

<img src="Mysql 实战.assets/image-20210517095308519.png" alt="image-20210517095308519" style="zoom:50%;" />



假设: 发生宕机，事务没提交，此时丢失了内存中的数据和redo log，事务失败，数据还是正确的，无影响。

我们要提交事务了，就要依据设置的策略先把redo 日志从 redo log buffer 刷入到磁盘文件里。

策略: innodb_flush_log_at_trx_commitu 参数

1. 设置为 0，提交事务不会把 redo log buffer 里的日志刷入磁盘。此时宕机，内存数据和日志全部丢失。
2. 设置为1，提交事务时，必须把 redo log 刷入磁盘，此时宕机，就算更新的数据还没刷入磁盘，但是redo log 刷入了磁盘，可以根据 redo log 来恢复内存中的数据。 

<img src="Mysql 实战.assets/image-20210517101515561.png" alt="image-20210517101515561" style="zoom:50%;" />

<img src="Mysql 实战.assets/image-20210517101529615.png" alt="image-20210517101529615" style="zoom:50%;" />



3. 设置为2，把redo log 写入磁盘文件对应的 os cache 内存缓存里，实际没到磁盘上。此时宕机，内存数据一样会丢失，会丢失一秒的数据。



准备提交事务，依据策略把 **binlog** 日志写入磁盘。

**binlog日志策略:** sync_binlog 参数

1. sync_binlog: 0 日志写入 os cache 内存缓存。机器宕机，会丢失数据。
2. sync_binlog: 1 强制提交事务的时候，binlog直接写入到磁盘文件里去。机器宕机，数据也可以恢复。



最后把本次更新对应的 binlog文件名称和这次更新的 binlog日志在文件中的位置都写入到 redo log 日志中，同时在redo log日志文件里写入一个 commit。最终完成了事务的提交。

```bash
binlog文件名称: 
binlog文件位置:
commit
```

这样做是为了保持 redo log和bin log一致的。



假设我们已经提交了事务

内存中id 为10的 name已经是 'xxx' 了。但是磁盘里的id 为10的name 还是 'zhangsan' 。此时就是脏数据。

mysql有一个io后台线程，会在某个时间，随机把内存 buffer pool中的修改后的脏数据刷回到磁盘上的数据文件。

<img src="Mysql 实战.assets/image-20210517140543363.png" alt="image-20210517140543363" style="zoom:50%;" />

哪怕mysql宕机了，也没关系，因为重启之后，可以根据 redo log 恢复之前提交事务的修改到内存中。把 id=10的name修改为 ‘xxx’，等合适的时机，io线程自然会把修改后的数据刷到磁盘。

**1234步骤属于更新阶段，56属于事务开始阶段**



**update语句执行流程总结**:

1. 先判断innodb的 buffer pool缓冲池里面是否有数据，如果没有就从磁盘读取,缓存到缓冲池，在更新前加独占锁。
2. 把更新前的值写到 undo日志里面，便于后面的回滚操作。
3. 在更新前先写 redo log 到redo log buffer里  innodb_flush_log_at_trx_commitu 参数为1,此时同步把redo log刷入到磁盘中。
4. 准备提交事务时，sync_binlog:1  binlog日志直接写入磁盘。并且在 redo log中写入这次事务的binlog 名称和位置 和 commit。事务提交完成，事务执行成功。
5. mysql后台io线程随机把内存中已经完成事务修改后的数据刷入到磁盘中。





**问题:**

<img src="Mysql 实战.assets/image-20210517133952268.png" alt="image-20210517133952268" style="zoom:50%;" />

当前事务提交了，但是其他事务可能还需要 undo log 读取旧版本的数据。

undo log 是回滚段，当没有事务需要使用这个 undo log 来进行版本号数据查询时会被清理。

### 3.事务

事务就是要保证一组数据库操作，要么全部成功，要么全部失败。

#### 3.1 隔离性与隔离级别

ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、**隔离性**、持久性）

隔离程度越大，效率越低。



事务隔离级别:

* 读未提交:  一个事务还没提交时，它对数据的更改，就能被其他事务看到。
* 读提交:  事务提交后，它做的更改才会被其他事务看到。
* 可重复读: 事务执行过程中看到的数据，和这个事务启动时看到的数据一致。
* 串行化: 写会加写锁，读会加读锁，出现冲突时，后访问的事务必须等前一个事务执行完成，才能继续执行



Oracle 数据库的默认隔离级别: 读提交

Mysql 数据库的默认隔离级别: 可重复读

对于一些从 Oracle 迁移到 MySQL 的应用，为保证数据库隔离级别的一致，你一定要记得将 MySQL 的隔离级别设置为“读提交”。



如何实现事务的隔离性:

MVCC：多版本并发控制，通过undo log版本链和read-view实现事务隔离 （可重复读）

同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）



假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。

<img src="Mysql 实战.assets/d9c313809e5ac148fc39feff532f0fee.png" alt="d9c313809e5ac148fc39feff532f0fee" style="zoom:50%;" />



当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。

对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。

在可重复读隔离级别中，表中的数据其实已经改变，在前面的视图里，需要查找某条记录时，是通过取当前数据，再取视图对应的回滚段回滚到该视图的值。

> **什么时候删除回滚日志(undo log) ?**

在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。

当系统里没有比这个回滚日志更早的 read-view 的时候。

> **基于上面的说明，我们来讨论一下为什么建议你尽量不要使用长事务。**

长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。

除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库。



MySQL 的事务启动方式:

* 显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。
* set autocommit=0，这个命令会将这个线程的自动提交关掉。执行select语句，事务也会启动，直到rollback或者 commit。

有些客户端连接框架会默认连接成功后先执行一个 set autocommit=0 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。

建议总是使用 set autocommit=1, 通过显式语句的方式来启动事务。





可以在 information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。

```mysql

select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60
```







脏读:  一个事务读取了另一个事务未提交的数据

不可重复读: 一个事务读取表中数据，多次读取结果不同

幻读: 一个事务读取到了别的事务插入的数据，导致前后读取不一致 





### 4.索引
